{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 10, 7, 4)\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv3D]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-f4f65b851803>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m   1133\u001b[0m           call_from_convolution=False)\n\u001b[1;32m   1134\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;31m# copybara:strip_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;31m# copybara:insert return self.conv_op(inp, filter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv3d\u001b[0;34m(input, filter, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1398\u001b[0m         return conv3d_eager_fallback(\n\u001b[1;32m   1399\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   1401\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv3d_eager_fallback\u001b[0;34m(input, filter, strides, padding, data_format, dilations, name, ctx)\u001b[0m\n\u001b[1;32m   1462\u001b[0m   \"data_format\", data_format, \"dilations\", dilations)\n\u001b[1;32m   1463\u001b[0m   _result = _execute.execute(b\"Conv3D\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1464\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1465\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m     _execute.record_gradient(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv3D]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.random.normal([1, 10, 10, 7, 4])\n",
    "print(inputs.shape)\n",
    "conv = tf.keras.layers.Conv3D(32, (7, 7, 5), strides=1, padding='same')\n",
    "outputs = conv(inputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0], [243, 248, 238], [254, 126, 125], [254, 95, 56], [142, 121, 56], [160, 212, 56], [219, 212, 56]]\n",
      "\n",
      "uint8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'channel')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RGB\n",
    "wall = [0, 0, 0]\n",
    "floor = [243, 248, 238]\n",
    "box_target = [254, 126, 125]\n",
    "box_on_target = [254, 95, 56]\n",
    "box = [142, 121, 56]\n",
    "player = [160, 212, 56]\n",
    "player_on_target = [219, 212, 56]\n",
    "\n",
    "surfaces = [wall, floor, box_target, box_on_target, box, player, player_on_target]\n",
    "print(surfaces)\n",
    "print()\n",
    "# print(observation[0:5, 0:5, :])\n",
    "# print()\n",
    "\n",
    "grid = np.zeros((10, 10, 7), dtype=np.uint8)\n",
    "\n",
    "plt.imshow(observation)\n",
    "#print(np.all(observation[0:5, 0:5, :] == surfaces[1], axis=2).astype(np.uint8))\n",
    "for si in range(len(surfaces)):\n",
    "    grid[..., si] = np.all(observation == surfaces[si], axis=2).astype(np.uint8)\n",
    "print(grid.dtype)\n",
    "plt.figure()\n",
    "plt.imshow(grid[..., 0]); plt.title('channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "(10, 10, 3)\n",
      "uint8\n",
      "10 10 3\n",
      "(10, 10, 3)\n",
      "-0.1\n",
      "False\n",
      "{'action.name': 'push left', 'action.moved_player': True, 'action.moved_box': False}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import gym_sokoban\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#env = gym.make('Sokoban-v0')\n",
    "env = gym.make('Boxoban-Train-v0')\n",
    "n_actions = env.action_space.n\n",
    "print(n_actions)\n",
    "\n",
    "env.reset()\n",
    "\n",
    "for _ in range(1000):\n",
    "    #plt.imshow(env.render(mode='tiny_rgb_array'))\n",
    "    frame = np.array(env.render(mode='tiny_rgb_array'))\n",
    "    print(frame.shape)\n",
    "    plt.imshow(frame)\n",
    "    #display.clear_output(wait=True)\n",
    "    #display.display(plt.gcf())\n",
    "    observation, reward, done, info = env.step(env.action_space.sample(), observation_mode='tiny_rgb_array')\n",
    "    plt.figure()\n",
    "    plt.imshow(np.array(observation)); plt.title('2')\n",
    "    print(observation.shape); print(reward); print(done); print(info)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bool'>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c569578d1c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#plt.imshow(env.render(mode='human'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#display.clear_output(wait=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2692\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many dimensions: %d > %d.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2694\u001b[0;31m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2695\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tobytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import gym_sokoban\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make('Sokoban-v0')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    env.render(mode='human')\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(type(env.render(mode='human')))\n",
    "    img = Image.fromarray(np.array(env.render(mode='human')), 'RGB')\n",
    "    #plt.imshow(env.render(mode='human'))\n",
    "    #display.clear_output(wait=True)\n",
    "    display.display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--rounds rounds] [--steps steps]\n",
      "                             [--env env] [--save] [--gifs]\n",
      "                             [--render_mode render_mode]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-75bf61a2-fa83-40ef-93c0-b60696e3f71a.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import gym_sokoban\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run environment with random selected actions.')\n",
    "parser.add_argument('--rounds', '-r', metavar='rounds', type=int,\n",
    "                    help='number of rounds to play (default: 1)', default=1)\n",
    "parser.add_argument('--steps', '-s', metavar='steps', type=int,\n",
    "                    help='maximum number of steps to be played each round (default: 300)', default=300)\n",
    "parser.add_argument('--env', '-e', metavar='env',\n",
    "                    help='Environment to load (default: Sokoban-v0)', default='Sokoban-v0')\n",
    "parser.add_argument('--save', action='store_true',\n",
    "                    help='Save images of single steps')\n",
    "parser.add_argument('--gifs', action='store_true',\n",
    "                    help='Generate Gif files from images')\n",
    "parser.add_argument('--render_mode', '-m', metavar='render_mode',\n",
    "                    help='Render Mode (default: human)', default='human')\n",
    "\n",
    "args = parser.parse_args()\n",
    "env_name = args.env\n",
    "n_rounds = args.rounds\n",
    "n_steps = args.steps\n",
    "save_images = args.save or args.gifs\n",
    "generate_gifs = args.gifs\n",
    "render_mode = args.render_mode\n",
    "observation_mode = 'tiny_rgb_array' if 'tiny' in render_mode else 'rgb_array'\n",
    "scale_image = 16\n",
    "\n",
    "# Creating target directory if images are to be stored\n",
    "if save_images and not os.path.exists('images'):\n",
    "    try:\n",
    "        os.makedirs('images')\n",
    "    except OSError:\n",
    "        print('Error: Creating images target directory. ')\n",
    "\n",
    "ts = time.time()\n",
    "env = gym.make(env_name)\n",
    "ACTION_LOOKUP = env.unwrapped.get_action_lookup()\n",
    "print(\"Created environment: {}\".format(env_name))\n",
    "\n",
    "\n",
    "def print_available_actions():\n",
    "    \"\"\"\n",
    "    Prints all available actions nicely formatted..\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    available_actions_list = []\n",
    "    for i in range(len(ACTION_LOOKUP)):\n",
    "        available_actions_list.append(\n",
    "            'Key: {} - Action: {}'.format(i, ACTION_LOOKUP[i])\n",
    "        )\n",
    "    display_actions = '\\n'.join(available_actions_list)\n",
    "    print()\n",
    "    print('Action out of Range!')\n",
    "    print('Available Actions:\\n{}'.format(display_actions))\n",
    "    print()\n",
    "\n",
    "\n",
    "for i_episode in range(n_rounds):\n",
    "    print('Starting new game!')\n",
    "    observation = env.reset()\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        env.render(render_mode, scale=scale_image)\n",
    "\n",
    "        action = input('Select action: ')\n",
    "        try:\n",
    "            action = int(action)\n",
    "\n",
    "            if not action in range(len(ACTION_LOOKUP)):\n",
    "                raise ValueError\n",
    "\n",
    "        except ValueError:\n",
    "            print_available_actions()\n",
    "            continue\n",
    "\n",
    "        observation, reward, done, info = env.step(action, observation_mode=observation_mode)\n",
    "        print(ACTION_LOOKUP[action], reward, done, info)\n",
    "        print(len(observation), len(observation[0]), len(observation[0][0]))\n",
    "        if save_images:\n",
    "            img = Image.fromarray(np.array(env.render(render_mode, scale=scale_image)), 'RGB')\n",
    "            img.save(os.path.join('images', 'observation_{}_{}.png'.format(i_episode, t)))\n",
    "\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            env.render(render_mode, scale=scale_image)\n",
    "            break\n",
    "\n",
    "    if generate_gifs:\n",
    "        print('')\n",
    "        import imageio\n",
    "\n",
    "        with imageio.get_writer(os.path.join('images', 'round_{}.gif'.format(i_episode)), mode='I', fps=1) as writer:\n",
    "\n",
    "                for t in range(n_steps):\n",
    "                    try:\n",
    "\n",
    "                        filename = os.path.join('images', 'observation_{}_{}.png'.format(i_episode, t))\n",
    "                        image = imageio.imread(filename)\n",
    "                        writer.append_data(image)\n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "env.close()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
